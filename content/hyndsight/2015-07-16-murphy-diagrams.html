---
author: robjhyndman
comments: true
date: 2015-07-16 07:57:46+00:00
mathjax: true
slug: murphy-diagrams
title: Murphy diagrams in R
categories:
- forecasting
- graphics
- R
- statistics
- time series
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>At the recent <a href="http://www.forecasters.org/isf"><em>International Symposium on Forecasting</em></a>, held in Riverside, California, Tillman Gneiting gave a great talk on <strong>“Evaluating forecasts: why proper scoring rules and consistent scoring functions matter”</strong>. It will be the subject of an IJF invited paper in due course.</p>
<p>One of the things he talked about was the “Murphy diagram” for comparing forecasts, as proposed in <a href="http://arxiv.org/abs/1503.08195">Ehm et al (2015)</a>. Here’s how it works for comparing mean forecasts.<!-- more --></p>
<p>It is well-known that the mean of the forecast distribution is obtained by minimizing the squared error loss function, <span class="math inline">\(S(x,y)=(x-y)^2\)</span> where <span class="math inline">\(x\)</span> is the point forecast and <span class="math inline">\(y\)</span> is the actual observation. That is
<span class="math display">\[
\text{E}(Y) = \text{min arg}_x S(x,y).
\]</span></p>
<p>An old result that is not so well known is that there are other loss functions which would also lead to the forecast mean. In fact, <a href="http://www.jstor.org/stable/2284229">Savage (1971)</a> showed that any scoring function is consistent for the mean if and only if it is of the form
<span class="math display">\[\begin{equation}\label{savage}
S(x,y) = \phi(y) - \phi(x) - \phi&#39;(x)(y-x)
\end{equation}\]</span>
where the function <span class="math inline">\(\phi\)</span> is convex with subgradient <span class="math inline">\(\phi&#39;\)</span>. Setting <span class="math inline">\(\phi(u)=u^2\)</span> gives the usual squared error result. So when comparing point forecasts that are intended to be estimates of the mean, it may not be appropriate to only compare the MSE values. A different scoring function that satisfies condition (1) may give a different ranking of competing forecasts.</p>
<p>Ehm et al (2015) showed that any scoring function satisfying condition (1) can be written as
<span class="math display">\[
S(x,y) = \int_{-\infty}^\infty S_{\theta}(x,y) dH(\theta)
\]</span>
where <span class="math inline">\(H\)</span> is a non-negative measure and
<span class="math display">\[
S_{\theta}(x,y) = \begin{cases}
  |y-\theta| &amp; \text{if} \min(x,y)\le\theta &lt; \max(x,y) \\
  0 &amp; \text{otherwise}.
\end{cases}
\]</span>
Different <span class="math inline">\(H\)</span> measures give different scoring functions, but <span class="math inline">\(S_{\theta}(x,y)\)</span> is the same for all such scoring functions.</p>
<p>So if we have point forecasts for <span class="math inline">\(n\)</span> events, we can calculate the average value of <span class="math inline">\(S_{\theta}(x,y)\)</span> for each <span class="math inline">\(\theta\)</span>:
<span class="math display">\[
s(\theta) = \frac{1}{n}\sum_{i=1}^n S_{\theta}(x_i,y_i)
\]</span>
and plot this as a function of <span class="math inline">\(\theta\)</span>. This is what Ehm et al call a “Murphy diagram”. A similar approach can be taken for quantile and expectile forecasts (with a different function <span class="math inline">\(S_\theta(x,y)\)</span> of course).</p>
<p>I have written some R code for producing these plots. Here it is applied to rolling one-step forecasts computed using ETS and ARIMA models. The data was simulated from an ARIMA model, so we would expect the ARIMA forecasts to be better:</p>
<pre class="r"><code>    source(&quot;https://robjhyndman.com/Rfiles/murphy.R&quot;)
    library(forecast)</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;quantmod&#39;:
##   method            from
##   as.zoo.data.frame zoo</code></pre>
<pre class="r"><code>    set.seed(2015)
    y &lt;- arima.sim(n = 300, list(ar = c(0.8897, -0.4858), ma = c(-0.2279, 0.2488)),
                   sd = sqrt(0.1796))

    # Rolling one-step forecasts
    f1 &lt;- f2 &lt;- ts(numeric(300)*NA)
    for(i in 30:299)
    {
      fit1 &lt;- ets(window(y,end=i))
      fit2 &lt;- auto.arima(window(y,end=i))
      f1[i+1] &lt;- forecast(fit1, PI=FALSE, h=1)$mean
      f2[i+1] &lt;- forecast(fit2, h=1)$mean
    }

    murphydiagram(y, f1, f2)
    legend(&quot;topleft&quot;, lty=1, col=c(&quot;blue&quot;,&quot;red&quot;), legend=c(&quot;ETS&quot;,&quot;ARIMA&quot;))</code></pre>
<p><img src="/hyndsight/2015-07-16-murphy-diagrams_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>    murphydiagram(y, f1, f2, type=&#39;diff&#39;, main=&quot;ETS - ARIMA&quot;)</code></pre>
<p><img src="/hyndsight/2015-07-16-murphy-diagrams_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<p>The shaded region shows 95% pointwise confidence intervals for the difference between the two functions.</p>
<p>Currently my R code only works for the mean function, but it would be easy enough to modify the function to handle quantiles and expectiles as well.</p>
